---
output:
  html_document: default
  pdf_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(knitr)
```

# Pre-Processing & Model Selection 

## Data Pre-Processing
From the EDA(Exploratory Data Analysis) and the variable description we found that there were no missing value. However, the variables were of different data type.

<<<<<<< HEAD

| Data Type                  | Variables                                      | Transformation | Technique           |
| -------------------------- | ---------------------------------------------- | -------------- |  -------------------|
| Numerical                  | Wife's age,   Number of children ever born     | Scaling        | Standard Scaling    |
| Ordinal                    | Wife's education, Husband Education,           | Encoding       | Ordinal Encoding    |
|                            | Husband's Occupation,Standard of living Index  |                |                     |
| Binary                     | Wife's religion, Wife working Media Exposure   | None           | Pass through        |


# Finding the best Model:

The target variable,( Contraceptive method used ), has three values:

1=No-use, 2=Long-term, 3=Short-term

For simiplicity we have made it a case of contraceptive usage or not. Hence, we combined 2=Long-term, 3=Short-term into one class and it was given a value of 1.  1=No-use was given a value of 0.
So now we have  0=No-use : 445 observations, 1=use : 586 observations. Now, it is binary classification problem. The model we tried:
=======
Based on the EDA (Exploratory Data Analysis) performed earlier and variable descriptions, it can be inferred that there are no missing values. However, the variables were of different data types. In order to perform operations on data, we need to ensure consistency of data types. *Define transformation*. The following table shows different variables in the dataset and the respective transformation performed on each of them.

| Data Type | Variable                                     | Transformation performed | Technique used       |
|-----------|-----------------------------------------------|----------------|------------------|
| Numerical | Wife's age, Number of children ever born      | Scaling        | Standard Scaling |
| Ordinal   | Wife's education, Husband Education,          | Encoding       | Ordinal Encoding |
|           | Husband's Occupation,Standard of living Index |                |                  |
| Binary    | Wife's religion, Wife working Media Exposure  | None           | Pass through     |

## Finding the best Model:
Our intent here is to find the probability of ___ and 
The target variable (Contraceptive method used) has three values:
```
1 = No-use
2 = Long-term, and
3 = Short-term
```

For simplicity and better model performance. We have combined `2 = Long-term`, `3 = Short-term` into one class and it was given a value of `1`. And the label `1 = No-use` was given a value of `0`, beacuse our aim is to predict the use(long or short)/ no use of contraceptives .

Our target distribution now have 
* `0 = No-use` : **445** observations, 
* `1 = use` : **586** observations.

With this data, our problem statement now turns into binary classification problem. The algorithms we used and tried in the process of finding the best model are:
>>>>>>> 415ea14d0397fd3bfa49bd45949c09eaeeb3a5c5

1. Decision Tree
2. kNN
3. Logistic Regression
4. RBF SVC

## Results of Cross Validation
<<<<<<< HEAD
From the Figure \@ref(tab:crossVal) It can be clearly seen than the RBF SVC is giving us the best score on both train and cross val dataset.
=======

From the table \@ref(tab:crossVal), it can be clearly inferred that the RBF SVC algorithm is giving us the best score on both training and cross val dataset. The metric used to evaluate the cross validation was **accuracy**.
>>>>>>> 415ea14d0397fd3bfa49bd45949c09eaeeb3a5c5

```{r crossVal, echo=FALSE }
cross_val <- read.csv("../results/val_score_results.csv") 
kable(cross_val, caption="Cross Validation Result (Score for Accuracy)")
```


<<<<<<< HEAD
## Hyper-Parameter Optimization
Since the performance of RBF SVC was the best we took it further for hyper-parameter tuning \@ref(tab:hyperparam). We found that the best parameters are:
C= 10.0
gamma = 0.01
=======
Given the performance of RBF SVC was the best, it was chosen for hyper-parameter tuning. The results of the top 5 models are shown in \@ref(tab:hyperparam). 

It can be observed that the best parameters are: `C = 10.0`, `gamma = 0.01`.
>>>>>>> 415ea14d0397fd3bfa49bd45949c09eaeeb3a5c5

```{r hyperparam, echo=FALSE}
hyperparameter <- read.csv("../results/Random_Search_results.csv") 
kable(hyperparameter, caption="Hyperparameter Selection")
```
